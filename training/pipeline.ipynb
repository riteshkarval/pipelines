{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dkube.sdk import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_token = os.getenv(\"DKUBE_USER_ACCESS_TOKEN\")\n",
    "user = os.getenv('USERNAME')\n",
    "code_name = \"tmdb\"\n",
    "train_fs = \"tmdb-train-fs\"\n",
    "test_fs  = \"tmdb-test-fs\"\n",
    "model_name = \"tmdb-model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = DkubeApi(token=existing_token)\n",
    "print(f\"Adding model {model_name}\")\n",
    "model = DkubeModel(user, name=model_name)\n",
    "try:\n",
    "    model.update_model_source(source='dvs')\n",
    "    api.create_model(model)\n",
    "except BaseException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = DkubeApi(token=existing_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import kfp\n",
    "import kfp.compiler as compiler\n",
    "import random\n",
    "import string\n",
    "\n",
    "generate = lambda hint: \"{}-{}\".format(hint, ''.join([random.choice(string.digits) for n in range(4)]))\n",
    "runid = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = kfp.Client(existing_token=existing_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"docker.io/ocdr/d3-datascience-sklearn:v0.23.2-1\"\n",
    "fs_inp_path = \"/opt/dkube/input\"\n",
    "model_out_path = \"/opt/dkube/output\"\n",
    "model_inp_path = \"/opt/dkube/model\"\n",
    "train_script = f\"cd training; python training.py --fs {train_fs}\"\n",
    "eval_script = f\"cd training; python evaluation.py --fs {test_fs}\"\n",
    "transformer_script = \"training/transformer.py\"\n",
    "serving_image = \"ocdr/sklearnserver:0.23.2\"\n",
    "framework = \"sklearn\"\n",
    "f_version = \"0.23.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components_url = \"/mnt/dkube/pipeline/components/\"\n",
    "dkube_training_op = kfp.components.load_component_from_file(components_url + \"training/component.yaml\")\n",
    "dkube_serving_op = kfp.components.load_component_from_file(components_url + \"serving/component.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(\n",
    "    name='dkube-train-pl',\n",
    "    description='example training pipeline to submit to leaderboard'\n",
    ")\n",
    "def training_pipeline(token):\n",
    "\n",
    "    train = dkube_training_op(token, json.dumps({\"image\": image}),\n",
    "                              framework=framework, version=f_version,\n",
    "                              program=code_name, run_script=train_script,\n",
    "                              featuresets=json.dumps([str(train_fs)]), outputs=json.dumps([str(model_name)]),\n",
    "                              input_featureset_mounts=json.dumps([fs_inp_path]),\n",
    "                              output_mounts=json.dumps([model_out_path])).set_display_name(\"Training\")\n",
    "    \n",
    "    evalt = dkube_training_op(token, json.dumps({\"image\": image}),\n",
    "                              framework=framework, version=f_version,\n",
    "                              program=code_name, run_script=eval_script,\n",
    "                              featuresets=json.dumps([str(test_fs)]),\n",
    "                              input_featureset_mounts=json.dumps([fs_inp_path]),\n",
    "                              models=json.dumps([str(model_name)]),\n",
    "                              input_model_mounts=json.dumps([model_inp_path])).after(train).set_display_name(\"Evaluation\")\n",
    "    \n",
    "    submit = dkube_serving_op(token, train.outputs['artifact'],\n",
    "                              device=\"cpu\", serving_image=json.dumps({\"image\": serving_image}),\n",
    "                              transformer_image=json.dumps({\"image\": image}),\n",
    "                              transformer_project=code_name,\n",
    "                              transformer_code=transformer_script).after(evalt).set_display_name(\"Serving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Dkube- Train pl'\n",
    "train_experiment = client.create_experiment(name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.compiler as compiler\n",
    "compiler.Compiler().compile(training_pipeline, \"train-pipeline.zip\")\n",
    "try:\n",
    "    pipeline = client.upload_pipeline(\"train-pipeline.zip\", pipeline_name = \"Train-pipeline\")\n",
    "except BaseException as e:\n",
    "    print(e)\n",
    "runid = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {\"token\":existing_token}\n",
    "run = client.run_pipeline(train_experiment.id, job_name=f\"[{pipeline.name}] Run\" + str(runid), pipeline_id=pipeline.id, params=arguments)\n",
    "runid += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}